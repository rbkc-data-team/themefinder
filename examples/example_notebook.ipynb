{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import themefinder\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the question the responses are answering and load the response data\n",
    "\n",
    "question = \"What improvements would you most like to see in local public transportation?\"\n",
    "\n",
    "responses = pd.read_json(\"./example_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe has the following columns: response_id, response\n",
    "# response_ids should start from 1\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LLM object for your use-case e.g. ChatGoogleGenerativeAI if using Google's Gemini or ChatAnthropic for Claude\n",
    "# NOTE: make sure your .env file is correctly set up with the correct API key/any other variables you need\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the whole pipeline end-to-end in one go.\n",
    "results = await themefinder.find_themes(\n",
    "    responses, \n",
    "    llm=llm, \n",
    "    question=question,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"themes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results of each stage of the pipeline can be viewed by accessing the keys of the returned dictionary e.g.\n",
    "results[\"themes\"]\n",
    "# or\n",
    "results[\"mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"themes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to modify the themes generated by the LLM such as merging similar themes or adding in new themes such as a default fallback theme like \"Other\", this can be done by directly modifying the themes and feeding them into the mapping stage of the pipeline.\n",
    "from themefinder import theme_mapping\n",
    "\n",
    "themes = results[\"themes\"][[\"topic_id\", \"topic\"]].copy()\n",
    "themes.loc[len(themes)] = {\"topic_id\": string.ascii_uppercase[len(themes)], \"topic\": \"Other: The response does not match any of the listed themes\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible for an LLM to be unable to process a response, if is too long or violates the models content filters, these responses can be reviewed in the 2nd element of the returned object for each task\n",
    "mapping, unprocessed = await theme_mapping(\n",
    "    responses,\n",
    "    llm=llm,\n",
    "    refined_themes_df=themes,\n",
    "    question=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To export the mapping to a spreadhseet\n",
    "mapping.to_excel(\"mapping.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
